# ML Courses
Courses taken in my ML journey

1. [Edx: Foundations of Data Analysis - Part 1](https://www.edx.org/course/foundations-of-data-analysis-part-1-statistics-usi): All projects & labs need to be done. Will help build R expertise and lower level knowledge of constructs
2. [Edx: Foundations of Data Analysis - Part 2](https://learning.edx.org/course/course-v1:UTAustinX+UT.7.20x+1T2016/home): Skimmed through this. 
3. [Coursera: Applied Machine learning in Python](https://www.coursera.org/learn/python-machine-learning/home/week/1): Good course to get to meaty topics by using Python & scikit library. The projects are good and give an estimation of what can be done and general code flow. This would also make you comfortable with Jupyter.
4. [Datacamp: Arima modeling with R](https://www.datacamp.com/blog/arima-modeling-with-r): Intro to time series modeling. Concepts are reusable in python as well.
5. [Datacamp: Unsupervised learning in python](https://app.datacamp.com/learn/courses/unsupervised-learning-in-python): Helped with doing analysis on clusters, visualizations etc.

10. [Udacity: Deep Learning](https://classroom.udacity.com/courses/ud730): Compressed and fast  & good workout on Tensorflow. Recommended only if you have basic understanding already.
11. [Udemy: Graph Neural Network](https://www.udemy.com/course/graph-neural-network/): Intro to GNN
12. [HuggingFace](https://huggingface.co/course): Intro to HuggingFace transformer for all the the text base AI.

### Domain specific course segues
1. [Datacamp: Machine Learning with PySpark](https://app.datacamp.com/learn/courses/machine-learning-with-pyspark): This is needed if you want to scale your ML knowledge to Apache Spark. Needed if you are working with a lot of data.
2. [Datacamp: Option trading with spreadsheets](https://app.datacamp.com/learn/courses/options-trading-in-spreadsheets): Took a course to understand financial basis for doing domain specific modeling.
3. [Datacamp: Introduction to Scala](https://app.datacamp.com/learn/courses/introduction-to-scala): Needed to interface bleeding edge scala libraries needed for pyspark ML training/inference.
4. [Coursera: Google Cloud Big Data and Machine Learning Fundamentals](https://www.coursera.org/learn/gcp-big-data-ml-fundamentals): To figure out the state of Google tools.
